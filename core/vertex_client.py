import vertexai
from vertexai.generative_models import GenerativeModel, Part
from config.settings import config
from typing import Optional

class VertexAIClient:
    """
    Client to interact with Vertex AI models.
    """

    def __init__(self):
        """
        Initializes the connection with Vertex AI.
        """
        vertexai.init(project=config.PROJECT_ID, location=config.LOCATION)
        self.model = GenerativeModel(config.MODEL_NAME)

    def analyze_pdf_content(self, gcs_uri: str, prompt_text: str) -> Optional[str]:
        """
        Send a PDF file (referenced in GCS) and a prompt to the model.

        Args:
            gcs_uri (str): File URI in GCS (e.g. gs://bucket/archivo.pdf).
            prompt_text (str): Prompt for the model.

        Returns:
            Optional[str]: Text response generated by the model or None if it fails.
        """
        try:
            # Create the reference to the PDF file in GCS
            pdf_file = Part.from_uri(
                uri=gcs_uri,
                mime_type="application/pdf"
            )

            # TODO revisar parametría del modelo para mayor poder analítico
            generation_config = {
                "max_output_tokens": 8192,
                "temperature": 0.2, # Bajo para respuestas más deterministas y técnicas
                "top_p": 0.95,
            }

            responses = self.model.generate_content(
                [pdf_file, prompt_text],
                generation_config=generation_config,
                stream=False
            )

            return responses.text
        except Exception as e:
            print(f"Error calling Vertex AI:{e}")
            return None